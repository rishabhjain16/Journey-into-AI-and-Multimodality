# Journey-to-Multimodality
This repository documents the ongoing exploration of multimodal AI, curating summaries of groundbreaking research that blends multiple sensory inputs like vision, sound, and language into unified AI systems. A journey into the future of AI perception and cognition.

## Table of Contents

| Project | Description | Link | Domain |
|---------|-------------|------|--------|
| VALLR | Visual ASR Language Model for Lip Reading | [üìÅ VALLR](./VALLR/) | VSR |
| AVFOrmer | Injecting Vision into Frozen Speech Models for Zero-Shot AV-ASR | [üìÅ AVFormer](./AVFormer/) | AVSR | 
