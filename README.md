# Journey-to-Multimodality
This repository documents the ongoing exploration of multimodal AI, curating summaries of groundbreaking research that blends multiple sensory inputs like vision, sound, and language into unified AI systems. A journey into the future of AI perception and cognition.

## Table of Contents

| Project | Description | Link | TASK |
|---------|-------------|------|--------|
| VALLR | Visual ASR Language Model for Lip Reading | [📁 VALLR](./VALLR/) | Visual Speech Recognition |
| AVFormer | Injecting Vision into Frozen Speech Models for Zero-Shot AV-ASR | [📁 AVFormer](./AVFormer/) | Audio Video Speech Recognition | 
| HTR-VT | Handwritten Text Recognition with Vision Transformer (uses CTC) | [📁 HTR-VT](./HTR-VT/) | Handwritten Text Recogntion | 
| AST | Audio Spectrogram Transformer| [📁 AST](./AST/) | Audio Classification | 
