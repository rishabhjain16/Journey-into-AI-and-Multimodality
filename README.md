# Journey-to-Multimodality
This repository chronicles the ongoing exploration of multimodal AI and Transformer models, curating summaries of groundbreaking research that integrates various sensory inputs such as vision, sound, and language into cohesive AI systems. It showcases some of the coolest and most exciting work happening in the field, highlighting cutting-edge advancements that blend multiple sensory modalities to expand the capabilities of AI. Additionally, this repository includes my personal notes and insights, making it easier to access and understand the latest research. Itâ€™s a journey into the future of AI perception and cognition, offering a curated resource for those eager to explore how AI is evolving to process and interact with the world in increasingly human-like ways.

<!--
Standard Template to Add things: 
| Model Name | Description | Link to Code or Paper | Task |
-->

<!--
Example 
| VALLR | Visual ASR Language Model for Lip Reading | [ğŸ“ VALLR](./VALLR/) | Visual Speech Recognition |
-->


## Interesting Papers: 

| Project | Description | Link | TASK |
|---------|-------------|----------|----------------|
| VALLR | Visual ASR Language Model for Lip Reading | [ğŸ“ VALLR](./VALLR/) | Visual Speech Recognition |
| AVFormer | Injecting Vision into Frozen Speech Models for Zero-Shot AV-ASR | [ğŸ“ AVFormer](./AVFormer/) | Audio Video Speech Recognition | 
| HTR-VT | Handwritten Text Recognition with Vision Transformer (uses CTC) | [ğŸ“ HTR-VT](./HTR-VT/) | Handwritten Text Recogntion | 
| AST | Audio Spectrogram Transformer| [ğŸ“ AST](./AST/) | Audio Classification | 
| LAVIS | A Library for Language-Vision Intelligence| [ğŸ“ LAVIS](./LAVIS/) | Language Vision - CLIP, BLIP, X-InstructBLIP, etc.| 
| Qwen2.5 - Omni | An end-to-end multimodal model designed to perceive diverse modalities, including text, images, audio, and video, while simultaneously generating text and natural speech responses in a streaming manner| [ğŸ“ Qwen2.5-Omni](./Omni/) | Multi-Modal LLM, MultiTask| 


## Blogs and Articles:
| Title | Link |
|-------|------|
| Understanding Multimodal LLMs | | [ğŸ“ Multimodal-LLM](./MultiLLM/) |


## Hugging Face Stuff: 
| Project | Description | Link | TASK |
|---------|-------------|------|------|
| VALLR | Visual ASR Language Model for Lip Reading | [ğŸ“ VALLR](./VALLR/) | TTS |
