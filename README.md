# Journey-to-Multimodality
This repository documents the ongoing exploration of multimodal AI, curating summaries of groundbreaking research that blends multiple sensory inputs like vision, sound, and language into unified AI systems. A journey into the future of AI perception and cognition.

## Table of Contents

| Project | Description | Link | Domain |
|---------|-------------|------|--------|
| VALLR | Visual ASR Language Model for Lip Reading | [ğŸ“ VALLR](./VALLR/) | VSR |
| AVFormer | Injecting Vision into Frozen Speech Models for Zero-Shot AV-ASR | [ğŸ“ AVFormer](./AVFormer/) | AVSR | 
| HTR-VT | Handwritten Text Recognition with Vision Transformer (uses CTC) | [ğŸ“ HTR-VT](./HTR-VT/) | HTR | 
